# Spike-IA

AutomaÃ§Ã£o completa da Spike IA

1. Backend (Node.js + Express + Firebase Functions)

Funcionalidades backend:

Recebe pedidos de criaÃ§Ã£o de vÃ­deo com tema e parÃ¢metros

Solicita roteiro via OpenAI GPT

Gera voz via TTS (Google Cloud TTS)

Gera thumbnail via DALLÂ·E

Monta vÃ­deo com ffmpeg (inserindo legenda, Ã¡udio e imagens)

Salva resultados no storage (Firebase Storage)

Notifica frontend via WebSocket ou polling status do job

Faz publicaÃ§Ã£o automÃ¡tica em redes sociais (API YouTube, Instagram etc)



---

CÃ³digo inicial backend (Node.js + Express + Firebase Functions)

// backend/index.js
const functions = require("firebase-functions");
const admin = require("firebase-admin");
const express = require("express");
const cors = require("cors");
const { Configuration, OpenAIApi } = require("openai");
const textToSpeech = require("@google-cloud/text-to-speech");
const { spawn } = require("child_process");
const fs = require("fs");
const path = require("path");

admin.initializeApp();
const db = admin.firestore();
const storage = admin.storage().bucket();

const app = express();
app.use(cors({ origin: true }));
app.use(express.json());

// ConfiguraÃ§Ã£o OpenAI
const openai = new OpenAIApi(new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
}));

// ConfiguraÃ§Ã£o Google TTS
const clientTTS = new textToSpeech.TextToSpeechClient();

app.post("/create-video", async (req, res) => {
  try {
    const { topic, style, length } = req.body;

    // 1. GeraÃ§Ã£o do roteiro
    const prompt = `Crie um roteiro educativo, estilo ${style}, sobre o tema: ${topic}, com duraÃ§Ã£o de ${length} minutos.`;
    const completion = await openai.createChatCompletion({
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
    });
    const script = completion.data.choices[0].message.content;

    // 2. GeraÃ§Ã£o da voz (TTS)
    const requestTTS = {
      input: { text: script },
      voice: { languageCode: "pt-BR", ssmlGender: "FEMALE" },
      audioConfig: { audioEncoding: "MP3" },
    };
    const [responseTTS] = await clientTTS.synthesizeSpeech(requestTTS);
    const audioBuffer = responseTTS.audioContent;

    const audioPath = path.join("/tmp", `audio-${Date.now()}.mp3`);
    fs.writeFileSync(audioPath, audioBuffer);

    // TODO: 3. Gerar thumbnail via DALLÂ·E (API chamada separada)
    // TODO: 4. Montar vÃ­deo com ffmpeg (inserir Ã¡udio, texto e thumbnail)

    // Placeholder resposta
    res.json({
      status: "process started",
      script,
      audioFile: audioPath,
    });

  } catch (error) {
    console.error(error);
    res.status(500).json({ error: error.message });
  }
});

exports.api = functions.https.onRequest(app);


---

2. Frontend (React)

Funcionalidades:

FormulÃ¡rio para enviar tema, estilo e duraÃ§Ã£o

Mostra status da geraÃ§Ã£o do vÃ­deo (loading, error, complete)

Visualiza roteiro gerado e player do Ã¡udio

Lista vÃ­deos gerados



---

CÃ³digo inicial frontend (React + Vite)

// frontend/src/App.jsx
import { useState } from "react";

export default function App() {
  const [topic, setTopic] = useState("");
  const [style, setStyle] = useState("educativo");
  const [length, setLength] = useState(5);
  const [status, setStatus] = useState("");
  const [script, setScript] = useState("");
  const [audioUrl, setAudioUrl] = useState("");

  const handleSubmit = async () => {
    setStatus("Gerando roteiro...");
    const res = await fetch("https://[seu-firebase-function-url]/create-video", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ topic, style, length }),
    });
    const data = await res.json();
    if (res.ok) {
      setScript(data.script);
      setAudioUrl(URL.createObjectURL(new Blob([data.audioFile])));
      setStatus("VÃ­deo em processamento...");
    } else {
      setStatus("Erro: " + data.error);
    }
  };

  return (
    <div>
      <h1>Spike IA - Gerador de VÃ­deos Educativos</h1>
      <input
        placeholder="Tema do vÃ­deo"
        value={topic}
        onChange={e => setTopic(e.target.value)}
      />
      <select value={style} onChange={e => setStyle(e.target.value)}>
        <option value="educativo">Educativo</option>
        <option value="informativo">Informativo</option>
        <option value="divertido">Divertido</option>
      </select>
      <input
        type="number"
        min={1}
        max={15}
        value={length}
        onChange={e => setLength(Number(e.target.value))}
      />
      <button onClick={handleSubmit}>Gerar VÃ­deo</button>

      <p>Status: {status}</p>
      {script && (
        <div>
          <h3>Roteiro Gerado</h3>
          <pre>{script}</pre>
          {audioUrl && <audio controls src={audioUrl} />}
        </div>
      )}
    </div>
  );
}


---

3. PrÃ³ximos passos para a automaÃ§Ã£o completa

Implementar geraÃ§Ã£o da thumbnail via DALLÂ·E com prompt baseado no tema

Criar funÃ§Ã£o para montagem automÃ¡tica de vÃ­deo usando ffmpeg (inserir legenda, Ã¡udio e imagem)

Criar sistema de fila para orquestrar etapas em segundo plano (Cloud Tasks ou RabbitMQ)

Integrar APIs das redes sociais para upload e publicaÃ§Ã£o automÃ¡tica

Desenvolver painel para monitorar status dos jobs e histÃ³rico

Criar app Android para controle e geraÃ§Ã£o mÃ³vel

// backend/index.js
const functions = require("firebase-functions");
const admin = require("firebase-admin");
const express = require("express");
const cors = require("cors");
const { Configuration, OpenAIApi } = require("openai");
const textToSpeech = require("@google-cloud/text-to-speech");
const { spawn } = require("child_process");
const fs = require("fs");
const path = require("path");

admin.initializeApp();
const db = admin.firestore();
const storage = admin.storage().bucket();

const app = express();
app.use(cors({ origin: true }));
app.use(express.json());

// ConfiguraÃ§Ã£o OpenAI
const openai = new OpenAIApi(new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
}));

// ConfiguraÃ§Ã£o Google TTS
const clientTTS = new textToSpeech.TextToSpeechClient();

app.post("/create-video", async (req, res) => {
  try {
    const { topic, style, length } = req.body;

    // 1. GeraÃ§Ã£o do roteiro
    const prompt = `Crie um roteiro educativo, estilo ${style}, sobre o tema: ${topic}, com duraÃ§Ã£o de ${length} minutos.`;
    const completion = await openai.createChatCompletion({
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
    });
    const script = completion.data.choices[0].message.content;

    // 2. GeraÃ§Ã£o da voz (TTS)
    const requestTTS = {
      input: { text: script },
      voice: { languageCode: "pt-BR", ssmlGender: "FEMALE" },
      audioConfig: { audioEncoding: "MP3" },
    };
    const [responseTTS] = await clientTTS.synthesizeSpeech(requestTTS);
    const audioBuffer = responseTTS.audioContent;

    const audioPath = path.join("/tmp", `audio-${Date.now()}.mp3`);
    fs.writeFileSync(audioPath, audioBuffer);

    // TODO: 3. Gerar thumbnail via DALLÂ·E (API chamada separada)
    // TODO: 4. Montar vÃ­deo com ffmpeg (inserir Ã¡udio, texto e thumbnail)

    // Placeholder resposta
    res.json({
      status: "process started",
      script,
      audioFile: audioPath,
    });

  } catch (error) {
    console.error(error);
    res.status(500).json({ error: error.message });
  }
});

exports.api = functions.https.onRequest(app);// frontend/src/App.jsx
import { useState } from "react";

export default function App() {
  const [topic, setTopic] = useState("");
  const [style, setStyle] = useState("educativo");
  const [length, setLength] = useState(5);
  const [status, setStatus] = useState("");
  const [script, setScript] = useState("");
  const [audioUrl, setAudioUrl] = useState("");

  const handleSubmit = async () => {
    setStatus("Gerando roteiro...");
    const res = await fetch("https://[seu-firebase-function-url]/create-video", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ topic, style, length }),
    });
    const data = await res.json();
    if (res.ok) {
      setScript(data.script);
      setAudioUrl(URL.createObjectURL(new Blob([data.audioFile])));
      setStatus("VÃ­deo em processamento...");
    } else {
      setStatus("Erro: " + data.error);
    }
  };

  return (
    <div>
      <h1>Spike IA - Gerador de VÃ­deos Educativos</h1>
      <input
        placeholder="Tema do vÃ­deo"
        value={topic}
        onChange={e => setTopic(e.target.value)}
      />
      <select value={style} onChange={e => setStyle(e.target.value)}>
        <option value="educativo">Educativo</option>
        <option value="informativo">Informativo</option>
        <option value="divertido">Divertido</option>
      </select>
      <input
        type="number"
        min={1}
        max={15}
        value={length}
        onChange={e => setLength(Number(e.target.value))}
      />
      <button onClick={handleSubmit}>Gerar VÃ­deo</button>

      <p>Status: {status}</p>
      {script && (
        <div>
          <h3>Roteiro Gerado</h3>
          <pre>{script}</pre>
          {audioUrl && <audio controls src={audioUrl} />}
        </div>
      )}
    </div>
  );
}// backend/index.js
const functions = require("firebase-functions");
const admin = require("firebase-admin");
const express = require("express");
const cors = require("cors");
const { Configuration, OpenAIApi } = require("openai");
const textToSpeech = require("@google-cloud/text-to-speech");
const fs = require("fs");
const path = require("path");

admin.initializeApp();
const app = express();
app.use(cors({ origin: true }));
app.use(express.json());

const openai = new OpenAIApi(new Configuration({ apiKey: process.env.OPENAI_API_KEY }));
const ttsClient = new textToSpeech.TextToSpeechClient();

app.post("/create-video", async (req, res) => {
  try {
    const { topic, style, length } = req.body;

    const prompt = `Crie um roteiro educativo estilo ${style} sobre o tema ${topic} com duraÃ§Ã£o de ${length} minutos.`;
    const completion = await openai.createChatCompletion({
      model: "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
    });
    const script = completion.data.choices[0].message.content;

    const ttsRequest = {
      input: { text: script },
      voice: { languageCode: "pt-BR", ssmlGender: "FEMALE" },
      audioConfig: { audioEncoding: "MP3" },
    };
    const [ttsResponse] = await ttsClient.synthesizeSpeech(ttsRequest);
    const audioBuffer = ttsResponse.audioContent;
    const audioPath = path.join("/tmp", `audio-${Date.now()}.mp3`);
    fs.writeFileSync(audioPath, audioBuffer);

    res.json({ script, audioFile: audioPath });
  } catch (e) {
    res.status(500).json({ error: e.message });
  }
});

exports.api = functions.https.onRequest(app);name: Spike IA CI/CD

on:
  push:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout do cÃ³digo
      uses: actions/checkout@v3
    - name: Configurar Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
    - name: Instalar dependÃªncias
      run: npm install
    - name: Rodar build
      run: npm run build# ðŸ‘¾ Spike IA

Bem-vindo ao perfil oficial da **Spike IA** â€” a inteligÃªncia artificial que cria automaticamente vÃ­deos educativos, com roteiro, voz, legenda e thumbnail.

## ðŸš€ Recursos
- GeraÃ§Ã£o de roteiros automÃ¡ticos
- Voz sintÃ©tica natural
- EdiÃ§Ã£o de vÃ­deo com legendas
- CriaÃ§Ã£o de thumbnails
- Upload automÃ¡tico para redes sociais
- PublicaÃ§Ã£o de APK Android na Play Store

## ðŸ“‚ Projetos Atuais
- **Spike IA Core** â†’ Backend + IA + AutomaÃ§Ã£o
- **Spike IA Web** â†’ Painel de controle online
- **Spike IA Mobile** â†’ Aplicativo Android

## ðŸ“« Contato
- E-mail: contato@spikeia.com
- Site: [www.spikeia.com](https://www.spikeia.com)

---
âœ¨ *Transformando ideias em vÃ­deos, automaticamente.*

